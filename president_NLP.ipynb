{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "president_NLP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshwinDeshpande96/Speech-Generation/blob/master/president_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJuPGQtSjp5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "169a84f9-3424-492a-900b-75ef008d6738"
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from google.colab import drive\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "import sys\n",
        "import inflect\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG5snBTtxKVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3ba08e49-f636-48ba-8099-e96509b57c3d"
      },
      "source": [
        "nltk.download(\"wordnet\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x243ce7Zj_is",
        "colab_type": "code",
        "outputId": "8ca7d35e-9d4d-4c64-b087-87bb3f417e12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#drive.mount('/content/gdrive', force_remount=True)\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90OaffXpkcPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "president = 'lincoln'\n",
        "file_path = '/content/gdrive/My Drive/Projects/NLP/President Speech/' +president+'_all.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-HfTCgojyJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_text = open(file_path).read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBLmMw1Kxq9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "porter = PorterStemmer()\n",
        "lancaster=LancasterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y-InccOo8TB",
        "colab_type": "code",
        "outputId": "ecf22298-62d7-47ba-ee47-4dd4767c9b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def text_preprocess(raw_text):\n",
        "    #raw_text = raw_text.lower()\n",
        "    num_set = re.findall(r'\\d+', raw_text)\n",
        "    p = inflect.engine()\n",
        "    #print num_set\n",
        "    for num in num_set:\n",
        "        word = str(p.number_to_words(num))\n",
        "        raw_text = raw_text.replace(num, word)\n",
        "    punctuation_chars = [\"!\", '\"', '&', ',', '?', '/', ':', ';', '<', '>', '$', '#', '@', '%', '*', '(', ')', '[', ']', '{', '}', '\\n', '-', '`'] \n",
        "    for symbol in punctuation_chars:\n",
        "        raw_text = raw_text.replace(symbol, ' ')\n",
        "    raw_text = raw_text.replace('.', ' . ')\n",
        "    raw_text = raw_text.replace( \"'\", \"\" )\n",
        "    \n",
        "    \n",
        "    raw_words = raw_text.split(' ')\n",
        "    raw_words = numpy.array([str(wordnet_lemmatizer.lemmatize(lancaster.stem(val))) for val in raw_words if val is not ''])\n",
        "    raw_words\n",
        "    print \"Text Word Count: \", raw_words.shape[0]\n",
        "    vocab = numpy.unique(sorted(raw_words))\n",
        "    print \"Vocab Length: \", vocab.shape[0]\n",
        "    return vocab.shape[0],raw_words.shape[0],raw_words, raw_text, vocab\n",
        "n_vocab, n_words, raw_words, raw_text, vocab = text_preprocess(raw_text)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text Word Count:  101118\n",
            "Vocab Length:  3737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRqptu503Vnp",
        "colab_type": "code",
        "outputId": "64735583-051a-4ff3-e2fe-8209e3e3d40d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "#vocab = numpy.delete(vocab, 0)\n",
        "print \"Vocab: \",vocab[:50], \"\\n...\\n\", vocab[-10:]\n",
        "print \"Raw Words: \",raw_words[:50], \"\\n...\\n\", raw_words[-10:]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab:  ['.' '00seven' '0eight' '0eightsix' '0eighty' '0fivenine' '0fivesix'\n",
            " '0fourfour' '0fournine' '0foursix' '0fourthree' '0nineteen' '0oneeight'\n",
            " '0onefive' '0oneone' '0seven' '0sevenseven' '0sevensix' '0six' '0sixfive'\n",
            " '0sixnine' '0threenine' '0two' '0two0' 'a' 'ab' 'abandon' 'abh' 'abid'\n",
            " 'abide' 'abl' 'ablest' 'abol' 'abolit' 'aborigin' 'about' 'abov'\n",
            " 'abraham' 'abridg' 'abroad' 'abrog' 'absolv' 'absorb' 'abstain'\n",
            " 'abstract' 'absurd' 'abund' 'abus' 'ac' 'academy'] \n",
            "...\n",
            "['yesterday' 'yet' 'yield' 'yo' 'york' 'you' 'young' 'yourselv' 'zeal'\n",
            " 'zero']\n",
            "Raw Words:  ['hon' 'to' 'henry' 'clayon' 'the' 'four' 'day' 'of' 'july' 'on'\n",
            " 'thousand' 'sev' 'hundr' 'and' 'seventy' 'six' 'the' 'peopl' 'of' 'a'\n",
            " 'few' 'feebl' 'and' 'oppress' 'colony' 'of' 'gre' 'britain' 'inhabit' 'a'\n",
            " 'port' 'of' 'the' 'atl' 'coast' 'of' 'nor' 'americ' 'publ' 'decl' 'their'\n",
            " 'nat' 'independ' 'and' 'mad' 'their' 'ap' 'to' 'the' 'just'] \n",
            "...\n",
            "['the' 'right' 'result' '.' 'yo' 'very' 'truly' '.' 'lincoln' '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE2KHJX9lEMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#chars = sorted(list(set(raw_text)))\n",
        "vocab_to_int = dict((c, i) for i, c in enumerate(vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18M8wcT5lbFv",
        "colab_type": "code",
        "outputId": "dcab1262-4fb7-49ef-ae36-6f2ef92f66f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_words - seq_length, 1):\n",
        "\tseq_in = raw_words[i:i + seq_length]\n",
        "\tseq_out = raw_words[i + seq_length]\n",
        "\tdataX.append([vocab_to_int[word] for word in seq_in])\n",
        "\tdataY.append(vocab_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print \"Total Patterns: \", n_patterns"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  101018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVBXfursnDoo",
        "colab_type": "code",
        "outputId": "89c7c6ce-a41b-4c4e-d3e7-c8a82b486962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print numpy.array(dataX).shape"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(114982, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKefWPepr3gJ",
        "colab_type": "code",
        "outputId": "44ae802f-c66e-4946-ab10-75bb44b9590b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "print X.shape\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(101018, 100, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-UH_UqZPVGg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ddab493-1ba7-4adc-8bbe-d9ef5381bfd4"
      },
      "source": [
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)\n",
        "print y.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(101018, 3737)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk_9ueRVsvyd",
        "colab_type": "code",
        "outputId": "23e3d51b-bb55-46cb-d2fb-a5f59cd30fa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(512, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1.0e-3))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-097iKSs8J90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhtW_JRgt8l_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"/content/gdrive/My Drive/Projects/NLP/President Speech/weights/\"+president+\"_weights.hdf5\"\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='loss', patience=10, verbose=0, mode='min'),\n",
        "    ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, verbose=1, mode='min'),\n",
        "    ModelCheckpoint(filepath, save_best_only=True,  save_weights_only=False, monitor='loss', mode='min')\n",
        "]\n",
        "#model.load_weights('/content/gdrive/My Drive/Projects/NLP/weights-improvement-20-1.9923.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0z-TplbBUTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = load_model('/content/gdrive/My Drive/Projects/NLP/President Speech/'+president+'_model.hdf5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MosMu16buKAm",
        "colab_type": "code",
        "outputId": "cca7cebc-0239-454c-acc8-0c79bc06605e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "#model.fit(X, y, epochs=1, batch_size=1000, callbacks=callbacks)\n",
        "#model.save('/content/gdrive/My Drive/Projects/NLP/President Speech/'+president+'_model.hdf5')\n",
        "for i in range(25):\n",
        "    model = load_model('/content/gdrive/My Drive/Projects/NLP/President Speech/'+president+'_model.hdf5')\n",
        "    model.fit(X, y, epochs=10, batch_size=64, callbacks=callbacks)\n",
        "    model.save('/content/gdrive/My Drive/Projects/NLP/President Speech/'+president+'_model.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "101018/101018 [==============================] - 658s 7ms/step - loss: 6.0508\n",
            "Epoch 2/10\n",
            "101018/101018 [==============================] - 643s 6ms/step - loss: 6.0288\n",
            "Epoch 3/10\n",
            "101018/101018 [==============================] - 632s 6ms/step - loss: 6.0250\n",
            "Epoch 4/10\n",
            "101018/101018 [==============================] - 625s 6ms/step - loss: 6.0250\n",
            "Epoch 5/10\n",
            "101018/101018 [==============================] - 662s 7ms/step - loss: 6.0253\n",
            "Epoch 6/10\n",
            "101018/101018 [==============================] - 624s 6ms/step - loss: 6.0235\n",
            "Epoch 7/10\n",
            "101018/101018 [==============================] - 636s 6ms/step - loss: 6.0245\n",
            "Epoch 8/10\n",
            "101018/101018 [==============================] - 628s 6ms/step - loss: 6.0253\n",
            "Epoch 9/10\n",
            "101018/101018 [==============================] - 625s 6ms/step - loss: 6.0284\n",
            "Epoch 10/10\n",
            "101018/101018 [==============================] - 621s 6ms/step - loss: 6.0216\n",
            "Epoch 1/10\n",
            "101018/101018 [==============================] - 634s 6ms/step - loss: 6.0258\n",
            "Epoch 2/10\n",
            " 89600/101018 [=========================>....] - ETA: 1:11 - loss: 6.0257"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfciOJS7QMot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "19d2db64-d5cc-4fbf-ff5f-e12ff5e5dffb"
      },
      "source": [
        "int_to_vocab = dict((i, c) for i, c in enumerate(vocab))\n",
        
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbSfmaaSRBUo",
        "colab_type": "code",
        "outputId": "e9439862-6c82-47a3-d006-cff0764dea24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "#start = len(dataX)-150\n",
        "pattern = dataX[start]\n",
        "print \"Seed:\"\n",
        "print \"\\\"\", ''.join([int_to_vocab[value] for value in pattern]), \"\\\"\"\n",
        "result = []\n",
        "# generate characters\n",
        "for i in range(40):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult.append(int_to_vocab[index])\n",
        "\tseq_in = [int_to_vocab[value] for value in pattern]\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print result\n",
        "print \"\\nDone.\""
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" toohavbeencomfromafric.ifthibesotheopofnewcountrytotheinstitutincreasthedemandforandaugthepricofslavandsodoeinfactmakslavoffreembycausthemtobebroughtfromafricandsoldintobond.buthowevthimaybeweknowtheopofnewcountrytoslaverytendtotheperpetuoftheinstitutandsodoekeepmeninslaverywhootherwwouldbefre. \"\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
